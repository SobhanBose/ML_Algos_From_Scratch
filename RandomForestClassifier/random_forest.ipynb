{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import decision_tree, utils\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../dataset/Student Stress Factors (2).csv\")\n",
    "dataset.columns = [\"Sleep Quality\", \"Headache Frequency\", \"Academic Performance\", \"Study Load\", \"Extracurricular Frequency\", \"Stress Level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoter:\n",
    "    def predict(self, models: list[decision_tree.DecisionTree], X: np.array) -> int:\n",
    "        \"\"\"\n",
    "        Make predictions based on simple majority\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : list[decision_tree.DecisionTree]\n",
    "        X : np.array\n",
    "            Data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        label: int\n",
    "        \"\"\"\n",
    "        predictions = {}\n",
    "        for model in models:\n",
    "            pred = model.make_prediction(X, model.root)\n",
    "            if pred in predictions.keys():\n",
    "                predictions[pred] += 1\n",
    "            else:\n",
    "                predictions[pred] = 1\n",
    "        \n",
    "        max_vote = max(predictions.values())\n",
    "        for label, votes in predictions.items():\n",
    "            if votes == max_vote:\n",
    "                return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators: int=100, max_depth: int=2, min_samples: int=2, bootstrap_sample_size: int=None, num_classes: int=2) -> None:\n",
    "        \"\"\"\n",
    "        Random Forest class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_estimators : int, optional\n",
    "            number of estimators, by default 100\n",
    "        max_depth : int, optional\n",
    "            max depth of each estimator, by default 2\n",
    "        min_samples : int, optional\n",
    "            minimum number of samples required in the leaf node, by default 2\n",
    "        num_classes : int, optional\n",
    "            number of output labels, by default 2\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples = min_samples\n",
    "        self.num_classes = num_classes\n",
    "        self.bootstrap_sample_size = bootstrap_sample_size\n",
    "        self.majority_voter = MajorityVoter()\n",
    "        self.estimators = [decision_tree.DecisionTree(min_samples=self.min_samples, max_depth=self.max_depth, num_classes=self.num_classes) \n",
    "                                for _ in range(n_estimators)]\n",
    "\n",
    "\n",
    "    def __getBootstrapSample(self, df: pd.DataFrame, sample_size: int=100) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get bootstrap data with replacement\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Dataset\n",
    "        sample_size : int, optional\n",
    "            Size of each sample, by default 100\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            Bootstrap Dataset\n",
    "        \"\"\"\n",
    "        row_indx = random.choices(df.index.to_list(), k=sample_size)\n",
    "\n",
    "        return df.loc[row_indx]\n",
    "    \n",
    "\n",
    "    def fit(self, df:pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Fit the estimators\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Dataset\n",
    "        \"\"\"\n",
    "        for estimator in self.estimators:\n",
    "            if self.bootstrap_sample_size:\n",
    "                bootstrap_dataset = self.__getBootstrapSample(df, self.bootstrap_sample_size)\n",
    "            else:\n",
    "                bootstrap_dataset = self.__getBootstrapSample(df, df.shape[0])\n",
    "\n",
    "            estimator.fit(bootstrap_dataset)\n",
    "\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Make predictions\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_hat: np.array\n",
    "            Output labels\n",
    "        \"\"\"\n",
    "        y_hat = [self.majority_voter.predict(self.estimators, x) for x in X.to_numpy()]\n",
    "        \n",
    "        return np.array(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = utils.train_valid_split(dataset, test_size=0.1, random_state=11)\n",
    "\n",
    "X_valid = validation_data.copy()\n",
    "y_valid = X_valid[\"Stress Level\"]\n",
    "X_valid.drop([\"Stress Level\"], axis=1, inplace=True)\n",
    "\n",
    "X_train = train_data.copy()\n",
    "y_train = X_train[\"Stress Level\"]\n",
    "X_train.drop([\"Stress Level\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForest(n_estimators=150, max_depth=20, bootstrap_sample_size=100, num_classes=5)\n",
    "rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score on Validation Set: 0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "pred = rf.predict(X_valid)\n",
    "print(f\"Accuracy Score on Validation Set: {utils.get_accuracy_score(y_valid, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on Validation Set: 0.9228500459621742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"F1 Score on Validation Set: {f1_score(y_valid, pred, average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import inf\n",
    "\n",
    "run = 0\n",
    "if run:\n",
    "    accuracy_vs_estimators = {\"x\": [], \"y\": []}\n",
    "    best_n_estimator = inf\n",
    "    highest_score = -inf\n",
    "\n",
    "    for n_estimators in range(1, 200, 10):\n",
    "        rf = RandomForest(n_estimators=n_estimators, max_depth=20, num_classes=5)\n",
    "        rf.fit(train_data)\n",
    "        pred = rf.predict(X_valid)\n",
    "        accuracy = utils.get_accuracy_score(y_valid, pred)\n",
    "        if accuracy>highest_score:\n",
    "            best_n_estimator = n_estimators\n",
    "            highest_score = accuracy\n",
    "\n",
    "        accuracy_vs_estimators[\"x\"].append(n_estimators)\n",
    "        accuracy_vs_estimators[\"y\"].append(accuracy)\n",
    "\n",
    "    plt.plot(accuracy_vs_estimators[\"x\"], accuracy_vs_estimators[\"y\"])\n",
    "    plt.xlabel(\"n_estimators\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(\"n_estimators vs Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 0\n",
    "if run:\n",
    "    accuracy_vs_max_depth = {\"x\": [], \"y\": []}\n",
    "    best_max_depth = inf\n",
    "    highest_score = -inf\n",
    "\n",
    "    for max_depth in range(2, 60, 5):\n",
    "        rf = RandomForest(n_estimators=best_n_estimator, max_depth=max_depth, num_classes=5)\n",
    "        rf.fit(train_data)\n",
    "        pred = rf.predict(X_valid)\n",
    "        accuracy = utils.get_accuracy_score(y_valid, pred)\n",
    "        if accuracy>highest_score:\n",
    "            best_max_depth = max_depth\n",
    "            highest_score = accuracy\n",
    "            \n",
    "        accuracy_vs_max_depth[\"x\"].append(max_depth)\n",
    "        accuracy_vs_max_depth[\"y\"].append(accuracy)\n",
    "\n",
    "    plt.plot(accuracy_vs_max_depth[\"x\"], accuracy_vs_max_depth[\"y\"])\n",
    "    plt.xlabel(\"max_depth\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.title(\"max_depth vs Accuracy\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
