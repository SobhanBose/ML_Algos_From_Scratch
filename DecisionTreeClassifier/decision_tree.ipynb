{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"./Student Stress Factors (2).csv\")\n",
    "dataset.columns = [\"Sleep Quality\", \"Headache Frequency\", \"Academic Performance\", \"Study Load\", \"Extracurricular Frequency\", \"Stress Level\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_valid_split(df: pd.DataFrame, test_size: float = 0.2, random_state: int=10) -> tuple:\n",
    "    \"\"\"\n",
    "    Performs train-validation split\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.DataFrame\n",
    "        Input Features\n",
    "    y: pd.DataFrame\n",
    "        Target Label\n",
    "    test_size: float, optional\n",
    "        Size of validation set, by default 0.2\n",
    "    random_state: int\n",
    "        Random State\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_data, valid_data\n",
    "    \"\"\"\n",
    "    random.seed(random_state)\n",
    "\n",
    "    test_size = round(test_size * len(df))\n",
    "    indices = df.index.tolist()\n",
    "\n",
    "    test_index = random.sample(indices, k=test_size)\n",
    "\n",
    "    train_data = df.drop(test_index)\n",
    "    valid_data = df.iloc[test_index]\n",
    "\n",
    "    return train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, threshold, left, right, info_gain):\n",
    "        self.is_leaf = False\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "class Leaf:\n",
    "    def __init__(self, value):\n",
    "        self.is_leaf = True\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples: int=3, max_depth: int=2, num_classes: int=2) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        min_samples: int, optional\n",
    "            by default 3\n",
    "        max_depth: int, optional\n",
    "            by default 2\n",
    "        num_classes: int, optional\n",
    "            by default 2\n",
    "        \"\"\"\n",
    "        \n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "\n",
    "    def __split(self, dataset: np.ndarray, feature: int, split_thresh: float) -> tuple:\n",
    "        \"\"\"\n",
    "        Splits data into left and right branches\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: np.ndarray\n",
    "            Data\n",
    "        indices: list\n",
    "            Active Indices\n",
    "        feature: int\n",
    "            Index of feature for splitting\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        left_indices: list\n",
    "        right_indices: list\n",
    "        \"\"\"\n",
    "\n",
    "        left_dataset = []\n",
    "        right_dataset = []\n",
    "\n",
    "        for row in dataset:\n",
    "            if row[feature] <= split_thresh:\n",
    "                left_dataset.append(row)\n",
    "            else:\n",
    "                right_dataset.append(row)\n",
    "\n",
    "        return np.array(left_dataset), np.array(right_dataset)\n",
    "    \n",
    "\n",
    "    def __get_entropy(self, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Computes the entropy\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y: np.ndarray\n",
    "            Label\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Entropy: float\n",
    "        \"\"\"\n",
    "\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        probabilities = counts / counts.sum()\n",
    "        entropy = sum(probabilities * -(np.log(probabilities)/np.log(self.num_classes)))\n",
    "        \n",
    "        return entropy\n",
    "    \n",
    "\n",
    "    def __get_information_gain(self, parent: np.ndarray, left: np.ndarray, right: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Get Information Gain\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        parent: np.ndarray\n",
    "            Parent Node\n",
    "        left: np.ndarray\n",
    "            Left Child\n",
    "        right: np.ndarray\n",
    "            Right Child\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        information_gain: float\n",
    "        \"\"\"\n",
    "\n",
    "        w_left = len(left)/len(parent)\n",
    "        w_right = len(right)/len(parent)\n",
    "\n",
    "        entropy_left, entropy_right = self.__get_entropy(left), self.__get_entropy(right)\n",
    "\n",
    "        weighted_entropy = w_left*entropy_left + w_right*entropy_right\n",
    "\n",
    "        information_gain = self.__get_entropy(parent) - weighted_entropy\n",
    "\n",
    "        return information_gain\n",
    "    \n",
    "\n",
    "    def __get_best_split(self, dataset: np.ndarray, num_features: int) -> dict:\n",
    "        \"\"\"\n",
    "        Get best split parameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: np.ndarray\n",
    "        num_features: int\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        best_split: dict\n",
    "            keys: gain, feature, threshold, left, right\n",
    "        \"\"\"\n",
    "\n",
    "        best_split = {'gain': -1, 'feature': None, 'split_thresh': None}\n",
    "\n",
    "        for feature_indx in range(num_features):\n",
    "            feature_values = dataset[:, feature_indx]\n",
    "            thresholds = np.unique(feature_values)\n",
    "            for threshold in thresholds:\n",
    "                left, right = self.__split(dataset, feature_indx, threshold)\n",
    "                if len(left) and len(right):\n",
    "                    y, left_y, right_y = dataset[:, -1], left[:, -1], right[:, -1]\n",
    "                    information_gain = self.__get_information_gain(y, left_y, right_y)\n",
    "                    if information_gain > best_split[\"gain\"]:\n",
    "                            best_split[\"feature\"] = feature_indx\n",
    "                            best_split[\"split_thresh\"] = threshold\n",
    "                            best_split[\"left\"] = left\n",
    "                            best_split[\"right\"] = right\n",
    "                            best_split[\"gain\"] = information_gain\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "\n",
    "    def __calculate_leaf_value(self, y: np.ndarray) -> int:\n",
    "        \"\"\"\n",
    "        Calculate Leaf Value\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y: np.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        leaf_value: int\n",
    "        \"\"\"\n",
    "\n",
    "        y = list(y)\n",
    "        return max(y, key=y.count)\n",
    "\n",
    "\n",
    "    def __build_tree_recur(self, dataset: np.ndarray, depth: int=0) -> Node:\n",
    "        \"\"\"\n",
    "        Build the decision tree recursively\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: np.ndarray\n",
    "        depth: int, optional\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        root: Node\n",
    "        \"\"\"\n",
    "\n",
    "        X, y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = X.shape\n",
    "\n",
    "        if num_samples >= self.min_samples and depth <= self.max_depth:\n",
    "            best_split = self.__get_best_split(dataset, num_features)\n",
    "            if best_split[\"gain\"] > 0:\n",
    "                left_subtree = self.__build_tree_recur(best_split[\"left\"], depth+1)\n",
    "                right_subtree = self.__build_tree_recur(best_split[\"right\"], depth+1)\n",
    "                \n",
    "                return Node(best_split[\"feature\"], best_split[\"split_thresh\"], \n",
    "                            left_subtree, right_subtree, best_split[\"gain\"])\n",
    "\n",
    "        leaf_value = self.__calculate_leaf_value(y)\n",
    "\n",
    "        return Leaf(leaf_value)\n",
    "    \n",
    "\n",
    "    def fit(self, dataset: pd.DataFrame) -> None:\n",
    "        \"\"\"\n",
    "        Fit model to data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataset: pd.DataFrame\n",
    "            Training Data\n",
    "        \"\"\"\n",
    "\n",
    "        self.root = self.__build_tree_recur(dataset.to_numpy())\n",
    "    \n",
    "\n",
    "    def __make_prediction(self, X: np.ndarray, node: Node):\n",
    "        if node.is_leaf: \n",
    "            return node.value\n",
    "        else:\n",
    "            feature = X[node.feature]\n",
    "            if feature <= node.threshold:\n",
    "                return self.__make_prediction(X, node.left)\n",
    "            else:\n",
    "                return self.__make_prediction(X, node.right)\n",
    "            \n",
    "            \n",
    "    def predict(self, X: pd.DataFrame) -> np.array:\n",
    "        \"\"\"\n",
    "        Make prediction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pd.DataFrame\n",
    "            Data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predictions: np.array\n",
    "            Output Label\n",
    "        \"\"\"\n",
    "        \n",
    "        preditions = [self.__make_prediction(x, self.root) for x in X.to_numpy()]\n",
    "        return np.array(preditions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_valid_split(dataset, test_size=0.1, random_state=10)\n",
    "\n",
    "X_valid = validation_data.copy()\n",
    "y_valid = X_valid[\"Stress Level\"]\n",
    "X_valid.drop([\"Stress Level\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree(min_samples=3, max_depth=20, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_score(y_true: pd.DataFrame, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Computes the accuracy of a classification model\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : pd.DataFrame\n",
    "        True Labels\n",
    "    y_pred : np.ndarray\n",
    "        Predicted Labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy_score: float\n",
    "        The accuracy of the model\n",
    "    \"\"\"\n",
    "\n",
    "    y_true = y_true.to_numpy().flatten()\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    return correct_predictions/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score: {get_accuracy_score(y_valid, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
